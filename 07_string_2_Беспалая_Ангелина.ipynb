{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4Pemaz9gLUL"
      },
      "source": [
        "# Введение в обработку текста на естественном языке"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9mSOlIKgLUP"
      },
      "source": [
        "Материалы:\n",
        "* Макрушин С.В. Лекция 9: Введение в обработку текста на естественном языке\\\n",
        "* https://realpython.com/nltk-nlp-python/\n",
        "* https://scikit-learn.org/stable/modules/feature_extraction.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4YAVIlcgLUS"
      },
      "source": [
        "## Задачи для совместного разбора"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-d4jeyfVgLUT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1791a7bc-0347-4d1e-b43a-d567ae9ce8ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: import: command not found\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "!import pymorphy2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRsx4KPBgLUU"
      },
      "source": [
        "1. Считайте слова из файла `litw-win.txt` и запишите их в список `words`. В заданном предложении исправьте все опечатки, заменив слова с опечатками на ближайшие (в смысле расстояния Левенштейна) к ним слова из списка `words`. Считайте, что в слове есть опечатка, если данное слово не содержится в списке `words`. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFerGbXygLUU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b1bd90a-6bb0-461b-d946-8d3a13e48e6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "с величайшим усилием выбравшись из потока убегающих людей кутузов со свитой уменьшившейся вдвое поехал на звуки выстрелов русских орудий \n"
          ]
        }
      ],
      "source": [
        "from nltk.metrics.distance import (\n",
        "edit_distance,\n",
        "edit_distance_align,\n",
        "binary_distance,\n",
        "jaccard_distance,\n",
        "masi_distance,\n",
        "interval_distance,\n",
        "custom_distance,\n",
        "presence,\n",
        "fractional_presence,\n",
        ")\n",
        "\n",
        "with open('litw-win.txt', encoding='cp1251') as f:\n",
        "    words = [l.split()[1] for l in f]\n",
        "text = '''с велечайшим усилием выбравшись из потока убегающих людей Кутузов со свитой уменьшевшейся вдвое поехал на звуки выстрелов русских орудий'''\n",
        "text_1 = ''\n",
        "for i in list(text.split()):\n",
        "    if i in words:\n",
        "        text_1 += i\n",
        "    else:\n",
        "        min = 1000\n",
        "        ind = 0\n",
        "        for j in range(len(words)):\n",
        "            a = edit_distance(i, words[j] )\n",
        "            if a<=min:\n",
        "                min = a\n",
        "                ind = j\n",
        "        text_1 += words[ind]\n",
        "    text_1 += ' '\n",
        "\n",
        "print(text_1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9TtB7tmgLUV"
      },
      "source": [
        "2. Разбейте текст из формулировки задания 1 на слова; проведите стемминг и лемматизацию слов."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_2 = text.split()"
      ],
      "metadata": {
        "id": "6tePwxITFtlE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7vFgAzsgLUV"
      },
      "source": [
        "3. Преобразуйте предложения из формулировки задания 1 в векторы при помощи `CountVectorizer`."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LlCivBEHiNUI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQf3DiIDgLUW"
      },
      "source": [
        "## Лабораторная работа 9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vd11DHPvgLUW"
      },
      "source": [
        "### Расстояние редактирования"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_mwX99LgLUX"
      },
      "source": [
        "1.1 Загрузите предобработанные описания рецептов из файла `preprocessed_descriptions.csv`. Получите набор уникальных слов `words`, содержащихся в текстах описаний рецептов (воспользуйтесь `word_tokenize` из `nltk`). "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np \n",
        "from nltk import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tquKHcOzPjcM",
        "outputId": "8120ea23-86b4-4acf-a3e2-5c9bf2be6704"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('preprocessed_descriptions.csv')\n",
        "words = set()\n",
        "\n",
        "for i in range(len(data)):\n",
        "    w = []\n",
        "    if type(data.preprocessed_descriptions[i])== str:\n",
        "        w.append(word_tokenize(data.preprocessed_descriptions[i]))\n",
        "    for j in range(len(w)):\n",
        "        words.update(w[j])\n",
        "words = list(words)\n",
        "print(words[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrIz8YQhGIM0",
        "outputId": "a22d79f4-1e84-4db1-c4cc-15febe6ad1eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['sitting', '7mg', 'ducasse', 'stephgerlette', 'efforti']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZNasmRIgLUX"
      },
      "source": [
        "1.2 Сгенерируйте 5 пар случайно выбранных слов и посчитайте между ними расстояние редактирования."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "for i in range(5):\n",
        "    a = random.randint(0,len(words))\n",
        "    b = random.randint(0,len(words))\n",
        "    c = edit_distance(words[a], words[b])\n",
        "    print(f'Между \"{words[a]}\" и \"{words[b]}\", {c} шагов')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCcKqNRuJCL3",
        "outputId": "4ea2d065-7f2a-4027-876f-0f228a1a142d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Между \"panel\" и \"cascarecce\", 8 шагов\n",
            "Между \"forefront\" и \"highersodium\", 10 шагов\n",
            "Между \"enjera\" и \"infinitum\", 8 шагов\n",
            "Между \"responders\" и \"smokehouse\", 9 шагов\n",
            "Между \"loxstyle\" и \"httpenlightenedcookingblogspotcom\", 29 шагов\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQJs1f-OgLUY"
      },
      "source": [
        "1.3 Напишите функцию, которая для заданного слова `word` возвращает `k` ближайших к нему слов из списка `words` (близость слов измеряется с помощью расстояния Левенштейна)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def funk(word,k):\n",
        "    global words\n",
        "    k1 = 0\n",
        "    s = []\n",
        "    while True:\n",
        "        for i in range(len(words)):\n",
        "            a = edit_distance(word, words[i] )\n",
        "            if a ==  k1:\n",
        "                s.append(words[i])\n",
        "            if len(s)>=k:\n",
        "                break\n",
        "        if len(s)>=k:\n",
        "            break\n",
        "        k1 +=1      \n",
        "    return s\n",
        "        \n",
        "\n",
        "funk(\"sitting\", 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWPht2aJQ6EI",
        "outputId": "60d75679-d642-4cba-c6ab-196b54456eb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sitting', 'fitting', 'setting']"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hs9sHJCUgLUY"
      },
      "source": [
        "### Стемминг, лемматизация"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xvklzkggLUY"
      },
      "source": [
        "2.1 На основе результатов 1.1 создайте `pd.DataFrame` со столбцами: \n",
        "    * word\n",
        "    * stemmed_word \n",
        "    * normalized_word \n",
        "\n",
        "Столбец `word` укажите в качестве индекса. \n",
        "\n",
        "Для стемминга воспользуйтесь `SnowballStemmer`, для нормализации слов - `WordNetLemmatizer`. Сравните результаты стемминга и лемматизации."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('stopwords')\n",
        "from nltk.stem import SnowballStemmer, WordNetLemmatizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BH2wI7L0j2cZ",
        "outputId": "cce2d64e-304e-470c-ddc9-d56e285cb245"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "col1 = [i for i in range(len(words))]\n",
        "sss = SnowballStemmer('english')\n",
        "col2 = [sss.stem(word) for word in words]\n",
        "lll = WordNetLemmatizer()\n",
        "col3 = [lll.lemmatize(word) for word in words]\n",
        "d = pd.DataFrame({'word': col1, 'stemmed_word':col2, 'normalized_word':col3}) \n",
        "d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "v-MMFd3RkT_y",
        "outputId": "bb58b210-5ffa-4067-86c8-1f7ca96abde8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        word  stemmed_word normalized_word\n",
              "0          0           sit         sitting\n",
              "1          1           7mg             7mg\n",
              "2          2        ducass         ducasse\n",
              "3          3  stephgerlett   stephgerlette\n",
              "4          4       efforti         efforti\n",
              "...      ...           ...             ...\n",
              "32863  32863       carrott         carrott\n",
              "32864  32864       reqular         reqular\n",
              "32865  32865         108mg           108mg\n",
              "32866  32866        canyou          canyou\n",
              "32867  32867       cristob       cristobal\n",
              "\n",
              "[32868 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-768fb632-ef68-4eeb-bdbc-a4d48cef9782\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>stemmed_word</th>\n",
              "      <th>normalized_word</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>sit</td>\n",
              "      <td>sitting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>7mg</td>\n",
              "      <td>7mg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>ducass</td>\n",
              "      <td>ducasse</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>stephgerlett</td>\n",
              "      <td>stephgerlette</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>efforti</td>\n",
              "      <td>efforti</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32863</th>\n",
              "      <td>32863</td>\n",
              "      <td>carrott</td>\n",
              "      <td>carrott</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32864</th>\n",
              "      <td>32864</td>\n",
              "      <td>reqular</td>\n",
              "      <td>reqular</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32865</th>\n",
              "      <td>32865</td>\n",
              "      <td>108mg</td>\n",
              "      <td>108mg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32866</th>\n",
              "      <td>32866</td>\n",
              "      <td>canyou</td>\n",
              "      <td>canyou</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32867</th>\n",
              "      <td>32867</td>\n",
              "      <td>cristob</td>\n",
              "      <td>cristobal</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>32868 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-768fb632-ef68-4eeb-bdbc-a4d48cef9782')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-768fb632-ef68-4eeb-bdbc-a4d48cef9782 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-768fb632-ef68-4eeb-bdbc-a4d48cef9782');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SU9oj8R7gLUZ"
      },
      "source": [
        "2.2. Удалите стоп-слова из описаний рецептов. Какую долю об общего количества слов составляли стоп-слова? Сравните топ-10 самых часто употребляемых слов до и после удаления стоп-слов."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words('english')\n",
        "print(stop_words)\n",
        "w = words\n",
        "before = len(w)\n",
        "for i in range(len(w)):\n",
        "    if w[i] in stop_words:\n",
        "        w.pop(i)\n",
        "        print('ddd')\n",
        "print(len(w), len(words))\n",
        "print('Доля от общего кол-ва: ', (len(words)-len(w))/len(w))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQUIY4ifr4TO",
        "outputId": "656e0eaf-34df-42f9-9809-ab6ddbd13405"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
            "32732 32732\n",
            "Доля от общего кол-ва:  0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmE_8RwfgLUZ"
      },
      "source": [
        "### Векторное представление текста"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rp17HVChgLUZ"
      },
      "source": [
        "3.1 Выберите случайным образом 5 рецептов из набора данных. Представьте описание каждого рецепта в виде числового вектора при помощи `TfidfVectorizer`"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "recipes = []\n",
        "with open(\"preprocessed_descriptions.csv\", \"r\") as file:\n",
        "    csvFile = csv.reader(file)\n",
        "    for row in csvFile:\n",
        "        recipes += [row[1]]\n"
      ],
      "metadata": {
        "id": "TOfdSHmaASmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLBVrI5ngLUZ"
      },
      "source": [
        "3.2 Вычислите близость между каждой парой рецептов, выбранных в задании 3.1, используя косинусное расстояние (`scipy.spatial.distance.cosine`) Результаты оформите в виде таблицы `pd.DataFrame`. В качестве названий строк и столбцов используйте названия рецептов."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5zxbQuGgLUZ"
      },
      "source": [
        "3.3 Какие рецепты являются наиболее похожими? Прокомментируйте результат (словами)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ea-Xtt-ugLUa"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}